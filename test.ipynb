{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader.dataset_loader import dataset_loader\n",
    "\n",
    "\n",
    "_, _, test_data_p = dataset_loader('cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(1) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(5) tensor([0., 1., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(6) tensor([0., 0., 1.])\n",
      "tensor(2) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(4) tensor([1., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(0) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n",
      "tensor(3) tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root=\"dataset\", name=\"Cora\", split=\"full\")\n",
    "dataset = dataset[0]  # there is only one graph in the dataset\n",
    "\n",
    "test_data = dataset.subgraph(dataset.test_mask)\n",
    "\n",
    "for i in range(len(test_data.y)):\n",
    "\tprint(test_data.y[i], test_data_p.y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dataset_loader.dataset_loader import dataset_loader\n",
    "\n",
    "\n",
    "DATASET_STORAGE_PATH = \"./dataset/\"\n",
    "\n",
    "train_data, val_data, test_data = dataset_loader('cora')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(149.)\n",
      "tensor(103.)\n",
      "tensor(64.)\n",
      "tensor(684.)\n"
     ]
    }
   ],
   "source": [
    "# count the how many elements are for each class (are 1-hot encoded)\n",
    "print(test_data.y[:,0].sum())\n",
    "print(test_data.y[:,1].sum())\n",
    "print(test_data.y[:,2].sum())\n",
    "print(test_data.y[:,3].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound:  [9.6062404e-06 9.9997389e-01 1.6473108e-05]\n",
      "Upper bound:  [9.62547260e-06 9.99973921e-01 1.65037596e-05]\n"
     ]
    }
   ],
   "source": [
    "from utils.math import interval_softmax, actually_reachable\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a_L = np.array([9.6062404e-06, 9.9997389e-01, 1.6473108e-05])\n",
    "a_U = np.array([9.6254726e-06, 9.9997395e-01, 1.6506086e-05])\n",
    "\n",
    "assert np.all(a_L <= a_U), \"Lower bound should be less than upper bound\"\n",
    "\n",
    "q_L, q_U = actually_reachable(a_L, a_U)\n",
    "\n",
    "assert np.all(q_L <= q_U), \"Lower bound should be less than upper bound\"\n",
    "\n",
    "print(\"Lower bound: \", q_L)\n",
    "print(\"Upper bound: \", q_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vast/m.tolloso/miniconda3/envs/gu/lib/python3.11/site-packages/ogb/nodeproppred/dataset.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_dict = torch.load(pre_processed_file_path)\n"
     ]
    }
   ],
   "source": [
    "from dataset_loader.dataset_loader import dataset_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = dataset_loader('ogb-arxiv-year', {\"batch_size\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader.dataset_loader import dataset_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = dataset_loader('cora', {\"batch_size\":1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([684, 3])\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "\tprint(data.y[data.y.sum(dim=1) == 0].shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ldh23TSY1PwXia6dU0MYcpyEgX-w3Hia\n",
      "From (redirected): https://drive.google.com/uc?id=1ldh23TSY1PwXia6dU0MYcpyEgX-w3Hia&confirm=t&uuid=ba1c433d-e201-4df7-96bc-2bde139b2938\n",
      "To: /vast/m.tolloso/graph-uncertainty/dataset/snap-patents.mat\n",
      "100%|██████████| 320M/320M [00:04<00:00, 69.3MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1dNs5E7BrWJbgcHeQ_zuy5Ozp2tRCWG0y\n",
      "From (redirected): https://drive.google.com/uc?id=1dNs5E7BrWJbgcHeQ_zuy5Ozp2tRCWG0y&confirm=t&uuid=52b85cec-d9cc-40e4-81ea-239e0886a23b\n",
      "To: /vast/m.tolloso/graph-uncertainty/dataset/pokec.mat\n",
      "100%|██████████| 1.35G/1.35G [00:35<00:00, 38.2MB/s]\n"
     ]
    },
    {
     "ename": "FileURLRetrievalError",
     "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1fAXtTVQS4CfEk4asqrFw9EPmlUPGbGtJ\n\nbut Gdown can't. Please check connections and permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/vast/m.tolloso/miniconda3/envs/gu/lib/python3.11/site-packages/gdown/download.py:267\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43mget_url_from_gdrive_confirmation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/vast/m.tolloso/miniconda3/envs/gu/lib/python3.11/site-packages/gdown/download.py:55\u001b[0m, in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot retrieve the public link of the file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may need to change the permission to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnyone with the link\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or have had many accesses. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset_drive_url \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 'twitch-gamer_feat' : '1fA9VIIEI8N0L27MSQfcBzJgRQLvSbrvR',\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# 'twitch-gamer_edges' : '1XLETC6dG3lVl7kDmytEJ52hvDMVdxnZ0',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1ySNspxbK-snNoAZM7oxiWGvOnTRdSyEK\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Wiki 1.9M\u001b[39;00m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m dataset_drive_url\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 14\u001b[0m \t\u001b[43mgdown\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET_STORAGE_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vast/m.tolloso/miniconda3/envs/gu/lib/python3.11/site-packages/gdown/download.py:278\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m         message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve file url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may still be able to access the file from the browser:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m             url_origin,\n\u001b[1;32m    277\u001b[0m         )\n\u001b[0;32m--> 278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(message)\n\u001b[1;32m    280\u001b[0m filename_from_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    281\u001b[0m last_modified_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1fAXtTVQS4CfEk4asqrFw9EPmlUPGbGtJ\n\nbut Gdown can't. Please check connections and permissions."
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "dataset_drive_url = {\n",
    "    # 'twitch-gamer_feat' : '1fA9VIIEI8N0L27MSQfcBzJgRQLvSbrvR',\n",
    "    # 'twitch-gamer_edges' : '1XLETC6dG3lVl7kDmytEJ52hvDMVdxnZ0',\n",
    "    'snap-patents' : '1ldh23TSY1PwXia6dU0MYcpyEgX-w3Hia', \n",
    "    'pokec' : '1dNs5E7BrWJbgcHeQ_zuy5Ozp2tRCWG0y', \n",
    "    'yelp-chi': '1fAXtTVQS4CfEk4asqrFw9EPmlUPGbGtJ', \n",
    "    'wiki_views': '1p5DlVHrnFgYm3VsNIzahSsvCD424AyvP', # Wiki 1.9M \n",
    "    'wiki_edges': '14X7FlkjrlUgmnsYtPwdh-gGuFla4yb5u', # Wiki 1.9M \n",
    "    'wiki_features': '1ySNspxbK-snNoAZM7oxiWGvOnTRdSyEK' # Wiki 1.9M\n",
    "}\n",
    "\n",
    "for key, value in dataset_drive_url.items():\n",
    "\tgdown.download(id=value, \\\n",
    "\t\toutput=f'{DATASET_STORAGE_PATH}/{key}.mat', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[647, 2325], edge_index=[2, 3763], y=[647, 3], train_mask=[647, 10], val_mask=[647, 10], test_mask=[647, 10], batch=[647], ptr=[2])\n",
      "tensor(218.)\n",
      "tensor(241.)\n",
      "tensor(188.)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "\tprint(batch)\n",
    "\tprint(batch.y[:,0].sum())\n",
    "\tprint(batch.y[:,1].sum())\n",
    "\tprint(batch.y[:,2].sum())\n",
    "\tprint(len(batch.y[batch.y.sum(dim=1) == 0]))\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringa = \"1fA9VIIEI8N0L27MSQfcBzJgRQLvSbrvR\"\n",
    "\n",
    "\"1fA9VIIEI8N0L27MSQfcBzJgRQLvSbrvR\" in stringa.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/yandex-research/heterophilous-graphs/raw/main/data/roman_empire.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import HeterophilousGraphDataset\n",
    "\n",
    "dataset = HeterophilousGraphDataset(root=\"dataset\", name=\"Roman-empire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])\n",
      "Class 0: 944 elements\n",
      "Class 1: 3163 elements\n",
      "Class 2: 3133 elements\n",
      "Class 3: 2502 elements\n",
      "Class 4: 2487 elements\n",
      "Class 5: 1359 elements\n",
      "Class 6: 1244 elements\n",
      "Class 7: 1080 elements\n",
      "Class 8: 852 elements\n",
      "Class 9: 789 elements\n",
      "Class 10: 717 elements\n",
      "Class 11: 445 elements\n",
      "Class 12: 428 elements\n",
      "Class 13: 365 elements\n",
      "Class 14: 329 elements\n",
      "Class 15: 319 elements\n",
      "Class 16: 312 elements\n",
      "Class 17: 2194 elements\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset[0]\n",
    "\n",
    "y = dataset[0].y\n",
    "\n",
    "# check the values of y\n",
    "print(y.unique())\n",
    "\n",
    "# print how many elements are for each class\n",
    "for i in range(y.max() + 1):\n",
    "\tprint(f\"Class {i}: {y[y == i].shape[0]} elements\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import ssl\n",
    "import sys\n",
    "import urllib\n",
    "from typing import Optional\n",
    "\n",
    "import fsspec\n",
    "\n",
    "from torch_geometric.io import fs\n",
    "\n",
    "\n",
    "def download_url(\n",
    "    url: str,\n",
    "    folder: str,\n",
    "    log: bool = True,\n",
    "    filename: Optional[str] = None,\n",
    "):\n",
    "    r\"\"\"Downloads the content of an URL to a specific folder.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL.\n",
    "        folder (str): The folder.\n",
    "        log (bool, optional): If :obj:`False`, will not print anything to the\n",
    "            console. (default: :obj:`True`)\n",
    "        filename (str, optional): The filename of the downloaded file. If set\n",
    "            to :obj:`None`, will correspond to the filename given by the URL.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = url.rpartition('/')[2]\n",
    "        filename = filename if filename[0] == '?' else filename.split('?')[0]\n",
    "\n",
    "    path = osp.join(folder, filename)\n",
    "\n",
    "    if fs.exists(path):  # pragma: no cover\n",
    "        if log and 'pytest' not in sys.modules:\n",
    "            print(f'Using existing file {filename}', file=sys.stderr)\n",
    "        return path\n",
    "\n",
    "    if log and 'pytest' not in sys.modules:\n",
    "        print(f'Downloading {url}', file=sys.stderr)\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    context = ssl._create_unverified_context()\n",
    "    data = urllib.request.urlopen(url, context=context)\n",
    "\n",
    "    with fsspec.open(path, 'wb') as f:\n",
    "        # workaround for https://bugs.python.org/issue42853\n",
    "        while True:\n",
    "            chunk = data.read(10 * 1024 * 1024)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def download_google_url(\n",
    "    id: str,\n",
    "    folder: str,\n",
    "    filename: str,\n",
    "    log: bool = True,\n",
    "):\n",
    "    r\"\"\"Downloads the content of a Google Drive ID to a specific folder.\"\"\"\n",
    "    url = f'https://drive.usercontent.google.com/download?id={id}&confirm=t'\n",
    "    return download_url(url, folder, log, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://drive.usercontent.google.com/download?id=1sncK996BM5lpuDf75lDFqCiDZyErc1c2&confirm=t\n",
      "Downloading https://drive.usercontent.google.com/download?id=1ZsHaJ0ussP1W722krmEIp_8pwKAoi5b3&confirm=t\n",
      "Downloading https://drive.usercontent.google.com/download?id=1JF3Pjv9OboMNYs2aXRQGbJbc4t_nDd5u&confirm=t\n",
      "Downloading https://drive.usercontent.google.com/download?id=1nJIKd77lcAGU4j-kVNx_AIGEkveIKz3A&confirm=t\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Optional, List\n",
    "import os.path as osp\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "class Reddit2(InMemoryDataset):\n",
    "    adj_full_id = '1sncK996BM5lpuDf75lDFqCiDZyErc1c2'\n",
    "    feats_id = '1ZsHaJ0ussP1W722krmEIp_8pwKAoi5b3'\n",
    "    class_map_id = '1JF3Pjv9OboMNYs2aXRQGbJbc4t_nDd5u'\n",
    "    role_id = '1nJIKd77lcAGU4j-kVNx_AIGEkveIKz3A'\n",
    "\n",
    "    def __init__(\n",
    "        self, root: str, transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None, force_reload: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform, pre_transform, force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        download_google_url(self.adj_full_id, self.raw_dir, 'adj_full.npz')\n",
    "        download_google_url(self.feats_id, self.raw_dir, 'feats.npy')\n",
    "        download_google_url(self.class_map_id, self.raw_dir, 'class_map.json')\n",
    "        download_google_url(self.role_id, self.raw_dir, 'role.json')\n",
    "\n",
    "    def process(self) -> None:\n",
    "        import scipy.sparse as sp\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        x = torch.from_numpy(np.load(osp.join(self.raw_dir, 'feats.npy'))).to(torch.float)\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        self.save([data], self.processed_paths[0])\n",
    "# --- End of Provided Class ---\n",
    "\n",
    "\n",
    "dataset = Reddit2(root='dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[232965, 602], edge_index=[2, 23213838], y=[232965], train_mask=[232965], val_mask=[232965], test_mask=[232965])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reddit2 Dataset ---\n",
      "Nodes for training (ID only): 44415\n",
      "Nodes for validation (ID only): 6356\n",
      "Nodes for testing (ID + OOD): 55334\n"
     ]
    }
   ],
   "source": [
    "from dataset_loader.dataset_loader import dataset_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = dataset_loader('reddit2', {\"batch_size\":1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0xe9d3fe491e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"/vast/m.tolloso/graph-uncertainty/dataset/roman_empire/roman_empire.npz\"\n",
    "\n",
    "# load the dataset\n",
    "\n",
    "data = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NpzFile.keys of NpzFile '/vast/m.tolloso/graph-uncertainty/dataset/roman_empire/roman_empire.npz' with keys: node_features, node_labels, edges, train_masks, val_masks...>\n"
     ]
    }
   ],
   "source": [
    "print(data.keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Keys ==\n",
      "['node_features', 'node_labels', 'edges', 'train_masks', 'val_masks', 'test_masks']\n",
      "\n",
      "== Node features ==\n",
      "Shape: (22662, 300), dtype: float32\n",
      "Example features (first row): [-0.04934495  0.09966621  0.02187826 -0.07259618  0.03880249  0.07354265\n",
      "  0.06273817  0.06120955 -0.05035826  0.01315369]\n",
      "\n",
      "== Node labels ==\n",
      "  Label 0: 944\n",
      "  Label 1: 3163\n",
      "  Label 2: 3133\n",
      "  Label 3: 2502\n",
      "  Label 4: 2487\n",
      "  Label 5: 1359\n",
      "  Label 6: 1244\n",
      "  Label 7: 1080\n",
      "  Label 8: 852\n",
      "  Label 9: 789\n",
      "  Label 10: 717\n",
      "  Label 11: 445\n",
      "  Label 12: 428\n",
      "  Label 13: 365\n",
      "  Label 14: 329\n",
      "  Label 15: 319\n",
      "  Label 16: 312\n",
      "  Label 17: 2194\n",
      "Num classes: 18, total nodes: 22662\n",
      "\n",
      "== Edges ==\n",
      "Shape: (32927, 2), dtype: int64\n",
      "Edges stored as shape (E, 2).\n",
      "Min node index: 0, max node index: 22661\n",
      "\n",
      "== train_masks ==\n",
      "Shape: (10, 22662), dtype: bool\n",
      "Interpreting as (splits, nodes). #splits=10, #nodes=22662\n",
      "True counts per split (first 10): [11331 11331 11331 11331 11331 11331 11331 11331 11331 11331]\n",
      "\n",
      "== val_masks ==\n",
      "Shape: (10, 22662), dtype: bool\n",
      "Interpreting as (splits, nodes). #splits=10, #nodes=22662\n",
      "True counts per split (first 10): [5665 5665 5665 5665 5665 5665 5665 5665 5665 5665]\n",
      "\n",
      "== test_masks ==\n",
      "Shape: (10, 22662), dtype: bool\n",
      "Interpreting as (splits, nodes). #splits=10, #nodes=22662\n",
      "True counts per split (first 10): [5666 5666 5666 5666 5666 5666 5666 5666 5666 5666]\n",
      "\n",
      "✅ Done. Copy the full output here so I can confirm the structure precisely.\n"
     ]
    }
   ],
   "source": [
    "# === Amazon Ratings Dataset Deep Summary ===\n",
    "NPZ_PATH = \"/vast/m.tolloso/graph-uncertainty/dataset/roman_empire/roman_empire.npz\"\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "npz = np.load(NPZ_PATH, allow_pickle=True)\n",
    "print(\"== Keys ==\")\n",
    "print(list(npz.keys()))\n",
    "\n",
    "# --- Node info ---\n",
    "x = npz[\"node_features\"]\n",
    "y = npz[\"node_labels\"].reshape(-1)\n",
    "edges = npz[\"edges\"]\n",
    "\n",
    "print(f\"\\n== Node features ==\")\n",
    "print(f\"Shape: {x.shape}, dtype: {x.dtype}\")\n",
    "print(f\"Example features (first row): {x[0][:10]}\")\n",
    "\n",
    "print(f\"\\n== Node labels ==\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  Label {u}: {c}\")\n",
    "print(f\"Num classes: {len(unique)}, total nodes: {len(y)}\")\n",
    "\n",
    "# --- Edge info ---\n",
    "E = np.asarray(edges)\n",
    "print(f\"\\n== Edges ==\")\n",
    "print(f\"Shape: {E.shape}, dtype: {E.dtype}\")\n",
    "if E.shape[0] == 2:\n",
    "    print(\"Edges stored as shape (2, E).\")\n",
    "elif E.shape[1] == 2:\n",
    "    print(\"Edges stored as shape (E, 2).\")\n",
    "else:\n",
    "    print(\"Unexpected edge shape!\")\n",
    "print(f\"Min node index: {E.min()}, max node index: {E.max()}\")\n",
    "\n",
    "# --- Mask info ---\n",
    "def summarize_mask(name, arr, expected_nodes):\n",
    "    arr = np.asarray(arr)\n",
    "    print(f\"\\n== {name} ==\")\n",
    "    print(f\"Shape: {arr.shape}, dtype: {arr.dtype}\")\n",
    "    if arr.ndim == 2:\n",
    "        print(f\"Interpreting as (splits, nodes). #splits={arr.shape[0]}, #nodes={arr.shape[1]}\")\n",
    "        true_counts = arr.sum(axis=1)\n",
    "        print(f\"True counts per split (first 10): {true_counts[:10]}\")\n",
    "        if arr.shape[1] != expected_nodes:\n",
    "            print(f\"⚠️  WARNING: columns ({arr.shape[1]}) != num_nodes ({expected_nodes})\")\n",
    "    elif arr.ndim == 1:\n",
    "        print(f\"1D mask with {arr.sum()} True values out of {arr.size}\")\n",
    "        if arr.size != expected_nodes:\n",
    "            print(f\"⚠️  WARNING: length {arr.size} != num_nodes {expected_nodes}\")\n",
    "\n",
    "if \"train_masks\" in npz:\n",
    "    summarize_mask(\"train_masks\", npz[\"train_masks\"], len(y))\n",
    "if \"val_masks\" in npz:\n",
    "    summarize_mask(\"val_masks\", npz[\"val_masks\"], len(y))\n",
    "if \"test_masks\" in npz:\n",
    "    summarize_mask(\"test_masks\", npz[\"test_masks\"], len(y))\n",
    "\n",
    "print(\"\\n✅ Done. Copy the full output here so I can confirm the structure precisely.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader.loader_roman_empire import load_roman_empire\n",
    "from dataset_loader.loader_amazon_ratings import load_amazon_ratings\n",
    "# cora\n",
    "from dataset_loader.loader_cora import loader_cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Roman Empire (ID train / ID+OOD val,test) ---\n",
      "N=22662, F=300, E=32927\n",
      "Split idx: 0 / 9\n",
      "ID classes: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]  | OOD classes: [0, 1, 2, 3, 4]\n",
      "Train(ID only): 5216\n",
      "Val(ID+OOD):    5665 -> 2609 ID, 3056 OOD\n",
      "Test(ID+OOD):   5666 -> 2608 ID, 3058 OOD\n",
      "Using GeoDataLoader for full-batch training.\n",
      "--- Amazon-Ratings (ID train / ID+OOD val,test) ---\n",
      "N=24492, F=300, E=93050\n",
      "Split idx: 0 / 9\n",
      "Train(ID only): 4461\n",
      "Val(ID+OOD):    6123 -> 2231 ID, 3892 OOD\n",
      "Test(ID+OOD):   6123 -> 2230 ID, 3893 OOD\n",
      "Using DataLoader for full-batch training.\n",
      "--- Cora Dataset with OOD Validation ---\n",
      "Nodes for training (ID only): 421\n",
      "Nodes for validation (ID+OOD): 500 -> 167 ID, 333 OOD\n",
      "Nodes for testing (ID+OOD): 1000 -> 316 ID, 684 OOD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch_geometric.loader.dataloader.DataLoader at 0xec1d89953c10>,\n",
       " <torch_geometric.loader.dataloader.DataLoader at 0xec1d8361b250>,\n",
       " <torch_geometric.loader.dataloader.DataLoader at 0xec1d837c9f50>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_roman_empire(\"./dataset/\", config = {} )\n",
    "load_amazon_ratings(\"./dataset/\", config = {} )\n",
    "loader_cora(\"./dataset/\", config = {} )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
